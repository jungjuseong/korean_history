# Chapter 1. Meet Kafka

모든 기업은 데이터를 기반으로 합니다. 우리는 정보를 받아들이고, 분석하고, 조작하고, 더 많은 것을 출력으로 만듭니다. 모든 애플리케이션은 로그 메시지, 메트릭, 사용자 활동, 발신 메시지 등 데이터를 생성합니다. 모든 데이터 바이트에는 다음에 해야 할 일을 알려주는 중요한 스토리가 있습니다. 그것이 무엇인지 알기 위해서는 데이터가 생성된 위치에서 분석할 수 있는 위치까지 데이터를 가져와야 합니다. 우리는 Amazon과 같은 웹사이트에서 매일 이것을 보고 있습니다. 여기에서 관심 항목에 대한 클릭은 나중에 우리에게 표시되는 추천 항목으로 바뀝니다.

이를 더 빨리 수행할수록 조직의 민첩성과 대응력이 향상될 수 있습니다. 데이터 이동에 드는 노력이 적을수록 당면한 핵심 비즈니스에 더 집중할 수 있습니다. 이것이 파이프라인이 데이터 중심 기업에서 중요한 구성 요소인 이유입니다. 데이터를 이동하는 방법은 데이터 자체만큼이나 중요합니다.

과학자들이 동의하지 않을 때마다 데이터가 충분하지 않기 때문입니다. 그런 다음 우리는 어떤 종류의 데이터를 얻을 것인지 동의할 수 있습니다. 우리는 데이터를 얻습니다. 데이터가 문제를 해결합니다. 내가 옳거나 당신이 옳거나 우리 둘 다 틀렸다. 그리고 계속 진행합니다.

  Neil deGrasse Tyson


## 발행/구독 메시징

Apache Kafka의 세부 사항을 논의하기 전에 게시/구독 메시징의 개념과 이것이 데이터 기반 애플리케이션의 중요한 구성 요소인 이유를 이해하는 것이 중요합니다. 발행/구독 메시징은 데이터(메시지)를 수신자에게 구체적으로 지시하지 않는 메시지의 게시자가 특징인 패턴입니다. 대신 게시자는 메시지를 어떻게든 분류하고 해당 구독자는 특정 클래스의 메시지를 수신하도록 구독합니다. Pub/Sub 시스템에는 이러한 패턴을 용이하게 하기 위해 메시지가 게시되는 중심 지점인 브로커가 있는 경우가 많습니다.

### 시작 방법
발행/구독에 대한 많은 사용 사례는 간단한 메시지 대기열 또는 프로세스 간 통신 채널과 같은 방식으로 시작됩니다. 예를 들어, 모니터링 정보를 어딘가에 보내야 하는 애플리케이션을 생성하여 그림 1-1과 같이 애플리케이션에서 대시보드에 메트릭을 표시하는 앱으로의 직접 연결을 열고 해당 연결을 통해 메트릭을 푸시합니다.

![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043072/files/assets/kdg2_0101.png)

그림 1-1. 단일 직접 측정항목 게시자

이것은 모니터링을 시작할 때 작동하는 간단한 문제에 대한 간단한 솔루션입니다. 머지 않아 메트릭을 장기적으로 분석하기로 결정했는데 대시보드에서 제대로 작동하지 않습니다. 메트릭을 수신하고 저장하고 분석할 수 있는 새 서비스를 시작합니다. 이를 지원하기 위해 두 시스템에 메트릭을 기록하도록 애플리케이션을 수정합니다. 지금까지 메트릭을 생성하는 애플리케이션이 세 개 더 있으며 모두 이 두 서비스에 대해 동일한 연결을 설정합니다. 동료는 알림을 위해 서비스에 대한 활성 폴링도 수행하는 것이 좋다고 생각하므로 요청 시 메트릭을 제공하기 위해 각 애플리케이션에 서버를 추가합니다. 잠시 후 이러한 서버를 사용하여 개별 메트릭을 얻고 다양한 목적으로 사용하는 더 많은 응용 프로그램이 있습니다. 이 아키텍처는 연결을 추적하기가 훨씬 더 어려운 그림 1-2와 매우 유사합니다.

![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043072/files/assets/kdg2_0102.png)

그림 1-2. 직접 연결을 사용하는 많은 메트릭 게시자

여기에 쌓인 기술 부채는 분명하므로 일부를 상환하기로 결정합니다. 모든 애플리케이션에서 메트릭을 수신하는 단일 애플리케이션을 설정하고 이를 필요로 하는 모든 시스템에 대해 해당 메트릭을 쿼리할 서버를 제공합니다. 이것은 아키텍처의 복잡성을 그림 1-3과 유사한 것으로 줄입니다. 축하합니다. 발행/구독 메시징 시스템을 구축했습니다!

![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043072/files/assets/kdg2_0103.png)

그림 1-3. 메트릭 게시/구독 시스템

### 개별 대기열 시스템
메트릭과의 전쟁을 벌이는 동시에 동료 중 한 명이 로그 메시지로 유사한 작업을 수행하고 있습니다. 다른 하나는 프론트엔드 웹사이트에서 사용자 행동을 추적하고 해당 정보를 기계 학습 작업을 하는 개발자에게 제공하고 관리용 보고서를 작성하는 작업을 하고 있습니다. 여러분은 모두 정보 게시자를 구독자에서 해당 정보로 분리하는 시스템을 구축하는 유사한 경로를 따랐습니다. 그림 1-4는 3개의 개별 게시/구독 시스템이 있는 이러한 인프라를 보여줍니다.

![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043072/files/assets/kdg2_0104.png)
그림 1-4. 다중 발행/구독 시스템

이것은 점대점 연결을 사용하는 것보다 확실히 훨씬 낫지만(그림 1-2에서와 같이), 많은 중복이 있습니다. 회사는 데이터를 대기시키기 위해 여러 시스템을 유지 관리하고 있으며 모두 고유한 버그와 제한 사항이 있습니다. 또한 곧 더 많은 메시징 사용 사례가 제공될 것임을 알고 있습니다. 당신이 원하는 것은 비즈니스가 성장함에 따라 성장할 일반 유형의 데이터를 게시할 수 있는 단일 중앙 집중식 시스템입니다.



## 카프카

Apache Kafka는 이 문제를 해결하기 위해 설계된 발행/구독 메시징 시스템으로 개발되었습니다. 이는 종종 "분산 커밋 로그" 또는 최근에는 "스트리밍 플랫폼 배포"로 설명됩니다. 파일 시스템 또는 데이터베이스 커밋 로그는 모든 트랜잭션에 대한 내구성 있는 기록을 제공하여 시스템 상태를 일관되게 구축하기 위해 재생할 수 있도록 설계되었습니다. 마찬가지로 Kafka 내의 데이터는 순서대로 영구적으로 저장되며 결정적으로 읽을 수 있습니다. 또한 데이터를 시스템 내에서 배포하여 장애에 대한 추가 보호는 물론 성능 확장을 위한 상당한 기회를 제공할 수 있습니다.

### 메시지 및 배치

Kafka 내의 데이터 단위를 메시지라고 합니다. 데이터베이스 배경에서 Kafka에 접근하는 경우 행이나 레코드와 유사하다고 생각할 수 있습니다. 메시지는 Kafka에 관한 한 단순히 바이트 배열이므로 그 안에 포함된 데이터는 Kafka에 대한 특정 형식이나 의미가 없습니다. 메시지에는 키라고 하는 선택적 메타데이터가 포함될 수 있습니다. 키도 바이트 배열이며 메시지와 마찬가지로 Kafka에 특별한 의미가 없습니다. 키는 메시지가 보다 제어된 방식으로 파티션에 기록될 때 사용됩니다. 가장 간단한 이러한 방식은 키의 일관된 해시를 생성한 다음 해당 항목의 총 파티션 수를 해시 모듈로 계산하여 해당 메시지에 대한 파티션 번호를 선택하는 것입니다. 이렇게 하면 동일한 키를 가진 메시지가 항상 동일한 파티션에 기록됩니다(파티션 수가 변경되지 않는 경우).

효율성을 위해 메시지는 일괄 처리로 Kafka에 기록됩니다. 일괄 처리는 동일한 주제 및 파티션에 대해 생성되는 메시지 모음일 뿐입니다. 각 메시지에 대해 네트워크를 통한 개별 왕복은 과도한 오버헤드를 초래하며 메시지를 일괄 처리로 수집하면 이를 줄일 수 있습니다. 물론 이것은 대기 시간과 처리량 간의 균형입니다. 배치가 클수록 단위 시간당 처리할 수 있는 메시지가 더 많아지지만 개별 메시지를 전파하는 데 더 오래 걸립니다. 또한 배치는 일반적으로 압축되어 일부 처리 능력을 희생시키면서 보다 효율적인 데이터 전송 및 저장을 제공합니다. 키와 일괄 처리는 모두 3장에서 자세히 설명합니다.

### 스키마

메시지는 Kafka 자체에 대해 불투명한 바이트 배열이지만 메시지 내용에 추가 구조 또는 스키마를 적용하여 쉽게 이해할 수 있도록 하는 것이 좋습니다. 애플리케이션의 개별 요구 사항에 따라 메시지 스키마에 사용할 수 있는 옵션이 많이 있습니다. JSON(JavaScript Object Notation) 및 XML(Extensible Markup Language)과 같은 단순한 시스템은 사용하기 쉽고 사람이 읽을 수 있습니다. 그러나 강력한 유형 처리 및 스키마 버전 간의 호환성과 같은 기능이 부족합니다. 많은 Kafka 개발자는 원래 Hadoop용으로 개발된 직렬화 프레임워크인 Apache Avro 사용을 선호합니다. Avro는 컴팩트 직렬화 형식, 메시지 페이로드와 분리되고 변경될 때 코드를 생성할 필요가 없는 스키마, 역방향 및 순방향 호환성을 갖춘 강력한 데이터 유형 지정 및 스키마 진화를 제공합니다.

일관된 데이터 형식은 메시지 쓰기와 읽기를 분리할 수 있으므로 Kafka에서 중요합니다. 이러한 작업이 밀접하게 결합되면 메시지를 구독하는 응용 프로그램을 업데이트하여 이전 형식과 병렬로 새 데이터 형식을 처리해야 합니다. 그래야만 메시지를 게시하는 애플리케이션이 새로운 형식을 활용하도록 업데이트될 수 있습니다. 잘 정의된 스키마를 사용하고 공통 저장소에 저장함으로써 Kafka의 메시지는 조정 없이 이해할 수 있습니다. 스키마 및 직렬화는 m에서 다룹니다.

### Topics and Partitions

Kafka의 메시지는 주제로 분류됩니다. 주제에 대한 가장 유사한 비유는 데이터베이스 테이블 또는 파일 시스템의 폴더입니다. 주제는 추가로 여러 파티션으로 나뉩니다. "커밋 로그" 설명으로 돌아가서 파티션은 단일 로그입니다. 메시지는 추가 전용 방식으로 기록되고 처음부터 끝까지 순서대로 읽힙니다. 주제에는 일반적으로 여러 파티션이 있으므로 단일 파티션 내에서 전체 주제에 대한 메시지 순서가 보장되지 않습니다. 그림 1-5는 각 파티션의 끝에 쓰기가 추가되는 4개의 파티션이 있는 주제를 보여줍니다. 파티션은 Kafka가 중복성과 확장성을 제공하는 방식이기도 합니다. 각 파티션은 다른 서버에서 호스팅될 수 있습니다. 즉, 단일 주제를 여러 서버에서 수평으로 확장하여 단일 서버의 능력을 훨씬 능가하는 성능을 제공할 수 있습니다. 또한 파티션을 복제할 수 있으므로 한 서버에 장애가 발생할 경우 다른 서버가 동일한 파티션의 복사본을 저장할 수 있습니다.

![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043072/files/assets/kdg2_0105.png)

그림 1-5. 여러 파티션이 있는 주제 표현

스트림이라는 용어는 Kafka와 같은 시스템 내에서 데이터를 논의할 때 자주 사용됩니다. 대부분의 경우 스트림은 파티션 수에 관계없이 단일 데이터 주제로 간주됩니다. 이는 생산자에서 소비자로 이동하는 단일 데이터 스트림을 나타냅니다. 메시지를 참조하는 이 방법은 스트림 처리를 논의할 때 가장 일반적입니다. 프레임워크(일부는 Kafka Streams, Apache Samza 및 Storm)가 메시지에서 실시간으로 작동할 때입니다. 이 작업 방식은 오프라인 프레임워크, 즉 Hadoop이 나중에 대량 데이터에 대해 작동하도록 설계된 방식과 비교할 수 있습니다. 스트림 처리의 개요는 14장에서 제공됩니다.

### 생산자와 소비자

Kafka 클라이언트는 시스템의 사용자이며 생산자와 소비자의 두 가지 기본 유형이 있습니다. 데이터 통합을 위한 Kafka Connect API와 스트림 처리를 위한 Kafka Streams와 같은 고급 클라이언트 API도 있습니다. 고급 클라이언트는 생산자와 소비자를 빌딩 블록으로 사용하고 상위 수준의 기능을 제공합니다.

생산자는 새 메시지를 만듭니다. 다른 발행/구독 시스템에서는 발행자 또는 작성자라고 부를 수 있습니다. 특정 주제에 대한 메시지가 생성됩니다. 기본적으로 생산자는 주제의 모든 파티션에 대해 균등하게 메시지 균형을 유지합니다. 어떤 경우에는 생산자가 특정 파티션으로 메시지를 보낼 것입니다. 이것은 일반적으로 메시지 키와 키의 해시를 생성하고 이를 특정 파티션에 매핑하는 파티셔너를 사용하여 수행됩니다. 이렇게 하면 주어진 키로 생성된 모든 메시지가 동일한 파티션에 기록됩니다. 생산자는 메시지를 파티션에 매핑하기 위한 다른 비즈니스 규칙을 따르는 사용자 지정 파티셔너를 사용할 수도 있습니다. 생산자는 3장에서 더 자세히 다룹니다.

소비자는 메시지를 읽습니다. 다른 발행/구독 시스템에서는 이러한 클라이언트를 구독자 또는 독자라고 할 수 있습니다. 소비자는 하나 이상의 주제를 구독하고 각 파티션에 생성된 순서대로 메시지를 읽습니다. 소비자는 메시지 오프셋을 추적하여 이미 소비한 메시지를 추적합니다. 오프셋(계속적으로 증가하는 정수 값)은 Kafka가 생성되는 각 메시지에 추가하는 메타데이터의 또 다른 부분입니다. 지정된 파티션의 각 메시지에는 고유한 오프셋이 있으며 다음 메시지에는 더 큰 오프셋이 있습니다(단조적으로 클 필요는 없음). 일반적으로 Kafka 자체에 각 파티션에 대해 가능한 다음 오프셋을 저장함으로써 소비자는 제자리를 잃지 않고 중지했다가 다시 시작할 수 있습니다.

소비자는 한 주제를 소비하기 위해 함께 일하는 한 명 이상의 소비자인 소비자 그룹의 일부로 작동합니다. 그룹은 각 파티션이 한 구성원만 사용하도록 합니다. 그림 1-6에는 한 주제를 소비하는 단일 그룹에 세 명의 소비자가 있습니다. 두 소비자는 각각 하나의 파티션에서 작업하고 세 번째 소비자는 두 파티션에서 작업합니다. 소비자를 파티션에 매핑하는 것을 소비자에 의한 파티션 소유권이라고 합니다.

이러한 방식으로 소비자는 메시지가 많은 주제를 소비하도록 수평적으로 확장할 수 있습니다. 또한 단일 소비자가 실패하면 그룹의 나머지 구성원이 누락된 구성원을 인계하기 위해 사용 중인 파티션을 재할당합니다. 소비자와 소비자 그룹은 4장에서 더 자세히 논의됩니다.

![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043072/files/assets/kdg2_0106.png)

그림 1-6. 토픽에서 읽는 소비자 그룹

### Brokers and Clusters

단일 Kafka 서버를 브로커라고 합니다. 브로커는 생산자로부터 메시지를 수신하고 오프셋을 할당하고 디스크의 저장소에 메시지를 씁니다. 또한 소비자에게 서비스를 제공하여 파티션에 대한 페치 요청에 응답하고 게시된 메시지에 응답합니다. 특정 하드웨어 및 성능 특성에 따라 단일 브로커가 초당 수천 개의 파티션과 수백만 개의 메시지를 쉽게 처리할 수 있습니다.

Kafka 브로커는 클러스터의 일부로 작동하도록 설계되었습니다. 브로커 클러스터 내에서 한 브로커는 클러스터 컨트롤러 역할도 합니다(클러스터의 라이브 구성원에서 자동으로 선택됨). 컨트롤러는 브로커에 파티션 할당 및 브로커 오류 모니터링을 포함한 관리 작업을 담당합니다. 파티션은 클러스터의 단일 브로커가 소유하며 해당 브로커를 파티션의 리더라고 합니다. 복제된 파티션(그림 1-7 참조)은 파티션의 팔로워라고 하는 추가 브로커에 할당됩니다. 복제는 파티션에서 메시지의 중복성을 제공하므로 브로커 오류가 있는 경우 팔로어 중 하나가 주도권을 인계받을 수 있습니다. 모든 생산자는 메시지를 게시하기 위해 리더에 연결해야 하지만 소비자는 리더 또는 팔로워 중 하나에서 가져올 수 있습니다. 파티션 복제를 포함한 클러스터 작업은 7장에서 자세히 다룹니다.

![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043072/files/assets/kdg2_0107.png)

그림 1-7. 클러스터의 파티션 복제

Apache Kafka의 주요 기능은 일정 기간 동안 메시지를 영구적으로 저장하는 보존 기능입니다. Kafka 브로커는 일정 기간(예: 7일) 동안 또는 파티션이 특정 바이트 크기(예: 1GB)에 도달할 때까지 메시지를 보존하는 주제에 대한 기본 보존 설정으로 구성됩니다. 이러한 제한에 도달하면 메시지가 만료되고 삭제됩니다. 이러한 방식으로 보존 구성은 언제든지 사용할 수 있는 최소 데이터 양을 정의합니다. 개별 주제는 메시지가 유용한 기간 동안만 저장되도록 고유한 보존 설정으로 구성할 수도 있습니다. 예를 들어 추적 주제는 며칠 동안 유지되는 반면 애플리케이션 메트릭은 몇 시간 동안만 유지될 수 있습니다. 주제를 로그 압축으로 구성할 수도 있습니다. 즉, Kafka는 특정 키로 생성된 마지막 메시지만 유지합니다. 이는 마지막 업데이트만 관심 있는 변경 로그 유형 데이터에 유용할 수 있습니다.

### 다중 클러스터

Kafka 배포가 증가함에 따라 여러 클러스터를 갖는 것이 종종 유리합니다. 이것이 유용할 수 있는 몇 가지 이유가 있습니다.

- 데이터 유형의 분리

- 보안 요구 사항에 대한 격리

- 다중 데이터 센터(재해 복구)

특히 여러 데이터 센터로 작업할 때는 데이터 센터 간에 메시지를 복사해야 하는 경우가 많습니다. 이러한 방식으로 온라인 응용 프로그램은 두 사이트의 사용자 활동에 액세스할 수 있습니다. 예를 들어 사용자가 프로필에서 공개 정보를 변경하는 경우 검색 결과가 표시되는 데이터 센터에 관계없이 해당 변경 사항이 표시되어야 합니다. 또는 모니터링 데이터를 여러 사이트에서 분석 및 경고 시스템이 호스팅되는 단일 중앙 위치로 수집할 수 있습니다. Kafka 클러스터 내의 복제 메커니즘은 여러 클러스터가 아닌 단일 클러스터 내에서만 작동하도록 설계되었습니다.

Kafka 프로젝트에는 다른 클러스터에 데이터를 복제하는 데 사용되는 MirrorMaker라는 도구가 포함되어 있습니다. 기본적으로 MirrorMaker는 대기열과 함께 연결된 Kafka 소비자 및 생산자입니다. 메시지는 한 Kafka 클러스터에서 사용되어 다른 클러스터로 생성됩니다. 그림 1-8은 MirrorMaker를 사용하여 두 로컬 클러스터의 메시지를 집계 클러스터로 집계한 다음 해당 클러스터를 다른 데이터 센터로 복사하는 아키텍처의 예를 보여줍니다. 애플리케이션의 단순한 특성은 정교한 데이터 파이프라인을 생성하는 능력에 달려 있으며, 이에 대해서는 9장에서 자세히 설명합니다.

![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043072/files/assets/kdg2_0108.png)

그림 1-8. 다중 데이터 센터 아키텍처

## 왜 카프카인가?

게시/구독 메시징 시스템에는 많은 선택이 있는데 Apache Kafka가 좋은 선택인 이유는 무엇입니까?

### 여러 생산자
Kafka는 클라이언트가 여러 주제를 사용하든 동일한 주제를 사용하든 상관없이 여러 생산자를 원활하게 처리할 수 있습니다. 따라서 시스템은 많은 프론트엔드 시스템에서 데이터를 집계하고 일관성을 유지하는 데 이상적입니다. 예를 들어 여러 마이크로 서비스를 통해 사용자에게 콘텐츠를 제공하는 사이트는 모든 서비스가 공통 형식을 사용하여 쓸 수 있는 페이지 보기에 대한 단일 주제를 가질 수 있습니다. 그러면 소비자 응용 프로그램은 각 응용 프로그램에 대해 하나씩 여러 주제에서 소비를 조정할 필요 없이 사이트의 모든 응용 프로그램에 대한 단일 페이지 보기 스트림을 수신할 수 있습니다.

### 다중 소비자
여러 생산자 외에도 Kafka는 여러 소비자가 다른 클라이언트를 방해하지 않고 단일 메시지 스트림을 읽을 수 있도록 설계되었습니다. 이것은 한 클라이언트에서 메시지를 사용하면 다른 클라이언트에서 사용할 수 없는 많은 대기열 시스템과 대조됩니다. 여러 Kafka 소비자는 그룹의 일부로 작동하도록 선택하고 스트림을 공유하여 전체 그룹이 주어진 메시지를 한 번만 처리하도록 할 수 있습니다.

### 디스크 기반 보존
Kafka는 여러 소비자를 처리할 수 있을 뿐만 아니라 지속적인 메시지 보존을 통해 소비자가 항상 실시간으로 작업할 필요는 없습니다. 메시지는 디스크에 기록되고 구성 가능한 보관 규칙에 따라 저장됩니다. 이러한 옵션은 주제별로 선택할 수 있으므로 소비자 요구에 따라 다양한 메시지 스트림의 보존 기간이 다릅니다. 영구 보존이란 처리 속도가 느리거나 트래픽이 급증하여 소비자가 뒤처져도 데이터 손실 위험이 없음을 의미합니다. 또한 메시지가 생산자에서 백업되거나 손실될 염려 없이 짧은 시간 동안 애플리케이션을 오프라인으로 전환하여 소비자에서 유지 관리를 수행할 수 있음을 의미합니다. 소비자는 중지될 수 있으며 메시지는 Kafka에 유지됩니다. 이를 통해 데이터 손실 없이 중단된 부분부터 처리 메시지를 다시 시작하고 선택할 수 있습니다.

### 확장 가능
Kafka의 유연한 확장성은 모든 양의 데이터를 쉽게 처리할 수 있도록 합니다. 사용자는 개념 증명으로 단일 브로커로 시작하여 3개의 브로커로 구성된 소규모 개발 클러스터로 확장하고 시간이 지남에 따라 데이터가 확장됨에 따라 증가하는 수십 또는 수백 개의 브로커로 구성된 더 큰 클러스터로 프로덕션으로 이동할 수 있습니다. 클러스터가 온라인 상태인 동안 확장을 수행할 수 있으며 전체 시스템 가용성에 영향을 미치지 않습니다. 이는 또한 여러 브로커의 클러스터가 개별 브로커의 오류를 처리하고 클라이언트에 서비스를 계속할 수 있음을 의미합니다. 더 많은 동시 실패를 허용해야 하는 클러스터는 더 높은 복제 요소로 구성할 수 있습니다. 복제는 7장에서 자세히 설명합니다.

### 고성능
이러한 모든 기능이 결합되어 Apache Kafka는 높은 부하에서도 뛰어난 성능을 제공하는 게시/구독 메시징 시스템이 됩니다. 생산자, 소비자 및 브로커는 모두 확장되어 매우 큰 메시지 스트림을 쉽게 처리할 수 있습니다. 이는 메시지 생성에서 소비자에게 가용성에 이르기까지 1초 미만의 메시지 대기 시간을 제공하면서 수행할 수 있습니다.

### 플랫폼 기능
핵심 Apache Kafka 프로젝트에는 개발자가 일반적인 유형의 작업을 훨씬 쉽게 수행할 수 있도록 하는 몇 가지 스트리밍 플랫폼 기능도 추가되었습니다. 일반적으로 YARN과 같은 구조화된 런타임 환경을 포함하는 전체 플랫폼은 아니지만 이러한 기능은 구축을 위한 견고한 기반과 실행할 수 있는 위치에 대한 유연성을 제공하는 API 및 라이브러리 형태입니다. Kafka Connect는 소스 데이터 시스템에서 데이터를 가져와 Kafka로 푸시하거나 Kafka에서 데이터를 가져와 싱크 데이터 시스템으로 푸시하는 작업을 지원합니다. Kafka Streams는 확장 가능하고 내결함성이 있는 스트림 처리 애플리케이션을 쉽게 개발하기 위한 라이브러리를 제공합니다. Connect는 9장에서 설명하고 Streams는 14장에서 자세히 설명합니다.

## 데이터 생태계

많은 애플리케이션이 데이터 처리를 위해 구축한 환경에 참여합니다. 우리는 데이터를 생성하거나 시스템에 데이터를 도입하는 애플리케이션의 형태로 입력을 정의했습니다. 메트릭, 보고서 및 기타 데이터 제품의 형태로 출력을 정의했습니다. 일부 구성 요소가 시스템에서 데이터를 읽고 다른 소스의 데이터를 사용하여 변환한 다음 다른 곳에서 사용할 데이터 인프라로 다시 도입하여 루프를 만듭니다. 이는 콘텐츠, 크기 및 사용 면에서 고유한 품질을 가진 다양한 유형의 데이터에 대해 수행됩니다.

Apache Kafka는 그림 1-9와 같이 데이터 생태계를 위한 순환 시스템을 제공합니다. 인프라의 다양한 구성원 간에 메시지를 전달하여 모든 클라이언트에 일관된 인터페이스를 제공합니다. 메시지 스키마를 제공하기 위해 시스템과 결합되면 생산자와 소비자는 더 이상 긴밀한 결합이나 모든 종류의 직접 연결이 필요하지 않습니다. 비즈니스 사례가 생성 및 해제됨에 따라 구성 요소를 추가 및 제거할 수 있으며 생산자는 누가 데이터를 사용하는지 또는 소비하는 응용 프로그램의 수에 대해 걱정할 필요가 없습니다.

![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043072/files/assets/kdg2_0109.png)

그림 1-9. 빅 데이터 생태계

### 사용 사례

활동 추적

LinkedIn에서 설계된 Kafka의 원래 사용 사례는 사용자 활동 추적입니다. 웹사이트의 사용자는 사용자가 취하는 작업에 관한 메시지를 생성하는 프런트엔드 애플리케이션과 상호 작용합니다. 이는 페이지 보기 및 클릭 추적과 같은 수동적 정보일 수도 있고 사용자가 프로필에 추가하는 정보와 같은 보다 복잡한 작업일 수도 있습니다. 메시지는 하나 이상의 주제에 게시된 다음 백엔드의 애플리케이션에서 사용됩니다. 이러한 응용 프로그램은 보고서 생성, 기계 학습 시스템 제공, 검색 결과 업데이트 또는 풍부한 사용자 경험을 제공하는 데 필요한 기타 작업을 수행할 수 있습니다.

메시징

Kafka는 애플리케이션이 사용자에게 알림(예: 이메일)을 보내야 하는 메시징에도 사용됩니다. 이러한 응용 프로그램은 형식이나 메시지가 실제로 전송되는 방식에 대해 걱정할 필요 없이 메시지를 생성할 수 있습니다. 단일 애플리케이션은 다음을 포함하여 보낼 모든 메시지를 읽고 일관되게 처리할 수 있습니다.

- 일반적인 모양과 느낌을 사용하여 메시지 형식 지정(데코레이션이라고도 함)

- 여러 메시지를 하나의 알림으로 모아서 보낼 수 있습니다.

- 메시지 수신 방법에 대한 사용자의 기본 설정 적용

이를 위해 단일 응용 프로그램을 사용하면 여러 응용 프로그램에서 기능을 복제할 필요가 없을 뿐만 아니라 가능하지 않은 집계와 같은 작업이 가능합니다.

측정항목 및 로깅

Kafka는 애플리케이션 및 시스템 메트릭 및 로그 수집에도 이상적입니다. 이것은 동일한 유형의 메시지를 생성하는 여러 애플리케이션을 가질 수 있는 기능이 빛나는 사용 사례입니다. 애플리케이션은 정기적으로 Kafka 주제에 메트릭을 게시하고 이러한 메트릭은 모니터링 및 경고를 위해 시스템에서 사용할 수 있습니다. 또한 Hadoop과 같은 오프라인 시스템에서 성장 예측과 같은 장기 분석을 수행하는 데 사용할 수도 있습니다. 로그 메시지는 동일한 방식으로 게시할 수 있으며 Elasticsearch 또는 보안 분석 애플리케이션과 같은 전용 로그 검색 시스템으로 라우팅할 수 있습니다. Kafka의 또 다른 추가 이점은 대상 시스템을 변경해야 할 때(예: 로그 스토리지 시스템을 업데이트해야 할 때) 프런트엔드 애플리케이션이나 집계 수단을 변경할 필요가 없다는 것입니다.

커밋 로그

Kafka는 커밋 로그의 개념을 기반으로 하기 때문에 데이터베이스 변경 사항을 Kafka에 게시할 수 있으며 애플리케이션은 이 스트림을 쉽게 모니터링하여 발생하는 실시간 업데이트를 받을 수 있습니다. 이 변경 로그 스트림은 데이터베이스 업데이트를 원격 시스템에 복제하거나 여러 애플리케이션의 변경 사항을 단일 데이터베이스 보기로 통합하는 데에도 사용할 수 있습니다. 내구성 보존은 여기서 변경 로그에 대한 버퍼를 제공하는 데 유용합니다. 또는 로그 압축 주제를 사용하여 키당 단일 변경 사항만 유지하여 더 긴 보존 기간을 제공할 수 있습니다.

스트림 처리

다양한 유형의 애플리케이션을 제공하는 또 다른 영역은 스트림 처리입니다. Kafka의 거의 모든 용도는 스트림 처리로 생각할 수 있지만 이 용어는 일반적으로 Hadoop에서 처리를 매핑/축소하기 위해 유사한 기능을 제공하는 애플리케이션을 지칭하는 데 사용됩니다. Hadoop은 일반적으로 몇 시간 또는 며칠에 걸친 장기간에 걸친 데이터 집계에 의존합니다. 스트림 처리는 메시지가 생성되는 즉시 실시간으로 데이터에 대해 작동합니다. 스트림 프레임워크를 사용하면 사용자가 Kafka 메시지에서 작동하는 작은 응용 프로그램을 작성하여 메트릭 계산, 다른 응용 프로그램의 효율적인 처리를 위한 메시지 분할 또는 여러 소스의 데이터를 사용하여 메시지 변환과 같은 작업을 수행할 수 있습니다. 스트림 처리는 14장에서 다룹니다.


## 카프카의 기원

Kafka는 LinkedIn의 데이터 파이프라인 문제를 해결하기 위해 만들어졌습니다. 다양한 유형의 데이터를 처리하고 사용자 활동 및 시스템 메트릭에 대한 깨끗하고 구조화된 데이터를 실시간으로 제공할 수 있는 고성능 메시징 시스템을 제공하도록 설계되었습니다.

데이터는 실제로 우리가 하는 모든 일에 힘을 실어줍니다.

Jeff Weiner, former CEO of LinkedIn

### LinkedIn’s Problem
이 장의 시작 부분에서 설명한 예와 유사하게 LinkedIn에는 데이터를 내부적으로 저장하고 표시하기 위해 사용자 지정 수집기와 오픈 소스 도구를 사용하는 시스템 및 애플리케이션 메트릭을 수집하는 시스템이 있었습니다. CPU 사용량 및 애플리케이션 성능과 같은 기존 메트릭 외에도 모니터링 시스템을 사용하고 단일 사용자 요청이 내부 애플리케이션을 통해 전파되는 방식에 대한 내부 검사를 제공할 수 있는 정교한 요청 추적 기능이 있었습니다. 그러나 모니터링 시스템에는 많은 결함이 있었습니다. 여기에는 폴링을 기반으로 하는 메트릭 수집, 메트릭 간의 큰 간격, 애플리케이션 소유자가 자체 메트릭을 관리할 수 있는 기능이 포함되지 않습니다. 이 시스템은 하이터치 방식이어서 가장 간단한 작업에 사람의 개입이 필요했으며, 여러 시스템에서 동일한 측정에 대해 다른 메트릭 이름으로 일관성이 없었습니다.

동시에 사용자 활동 정보를 추적하기 위한 시스템이 만들어졌습니다. 이것은 프론트엔드 서버가 주기적으로 연결하고 HTTP 서비스에 일괄 메시지(XML 형식)를 게시하는 HTTP 서비스였습니다. 그런 다음 이러한 배치는 파일이 구문 분석되고 대조되는 오프라인 처리 플랫폼으로 이동되었습니다. 이 시스템에는 많은 결함이 있었습니다. XML 형식이 일관되지 않았고 구문 분석에 계산 비용이 많이 들었습니다. 추적된 사용자 활동 유형을 변경하려면 프런트엔드와 오프라인 처리 간에 상당한 양의 조정 작업이 필요했습니다. 그럼에도 불구하고 시스템은 스키마 변경으로 인해 지속적으로 중단됩니다. 트래킹은 매시간 일괄처리로 구축되어 실시간으로 사용할 수 없었습니다.

모니터링 및 사용자 활동 추적은 동일한 백엔드 서비스를 사용할 수 없습니다. 모니터링 서비스가 너무 투박하고, 데이터 형식이 활동 추적에 적합하지 않았으며, 모니터링을 위한 폴링 모델이 추적을 위한 푸시 모델과 호환되지 않았습니다. 동시에 추적 서비스는 너무 취약하여 메트릭에 사용할 수 없었고 일괄 처리 중심의 처리는 실시간 모니터링 및 경고에 적합한 모델이 아니었습니다. 그러나 모니터링 및 추적 데이터는 많은 특성을 공유했으며 정보의 상관 관계(예: 특정 유형의 사용자 활동이 애플리케이션 성능에 미치는 영향)가 매우 바람직했습니다. 특정 유형의 사용자 활동이 감소하면 서비스를 제공한 애플리케이션에 문제가 있음을 나타낼 수 있지만 활동 배치 처리가 몇 시간 지연되면 이러한 유형의 문제에 대한 응답이 느려집니다.

처음에는 기존의 기성 오픈 소스 솔루션을 철저히 조사하여 데이터에 대한 실시간 액세스를 제공하고 필요한 메시지 트래픽 양을 처리하도록 확장할 수 있는 새로운 시스템을 찾았습니다. 프로토타입 시스템은 ActiveMQ를 사용하여 설정되었지만 당시에는 규모를 처리할 수 없었습니다. 또한 LinkedIn이 이를 사용하는 데 필요한 방식에 대한 취약한 솔루션이었습니다. ActiveMQ에서 브로커를 일시 중지할 수 있는 많은 결함을 발견했습니다. 이러한 일시 중지는 클라이언트에 대한 연결을 백업하고 사용자에게 요청을 제공하는 응용 프로그램의 기능을 방해합니다. 데이터 파이프라인을 위한 맞춤형 인프라로 진행하기로 결정했습니다.

### 카프카의 탄생
LinkedIn의 개발 팀은 이전에 분산 키-값 저장 시스템인 Voldemort의 개발 및 오픈 소스 릴리스를 담당한 수석 소프트웨어 엔지니어 Jay Kreps가 이끌었습니다. 초기 팀에는 Neha Narkhede와 나중에 Jun Rao도 포함되었습니다. 그들은 함께 모니터링 및 추적 시스템의 요구 사항을 모두 충족하고 미래를 위해 확장할 수 있는 메시징 시스템을 만들기 시작했습니다. 주요 목표는 다음과 같습니다.

- 푸시풀 모델을 이용하여 생산자와 소비자를 분리

- 여러 소비자를 허용하기 위해 메시징 시스템 내에서 메시지 데이터에 대한 지속성을 제공합니다.

- 높은 메시지 처리량에 최적화

- 데이터 스트림이 증가함에 따라 시스템의 수평적 확장을 허용합니다.

그 결과 메시징 시스템의 일반적인 인터페이스를 갖지만 로그 집계 시스템과 더 유사한 스토리지 계층을 가진 발행/구독 메시징 시스템이 탄생했습니다. 메시지 직렬화를 위한 Apache Avro의 채택과 함께 Kafka는 매일 수십억 개의 메시지 규모에서 메트릭과 사용자 활동 추적을 모두 처리하는 데 효과적이었습니다. Kafka의 확장성은 LinkedIn의 사용량이 7조 개 이상의 메시지를 생성하고(2020년 2월 기준) 매일 5페타바이트 이상의 데이터를 소비하는 데 도움이 되었습니다.

### 오픈 소스
Kafka는 2010년 말 GitHub에 오픈 소스 프로젝트로 출시되었습니다. 오픈 소스 커뮤니티에서 주목을 받기 시작하면서 2011년 7월에 Apache Software Foundation 인큐베이터 프로젝트로 제안되어 승인되었습니다. Apache Kafka는 2012년 10월. 그 이후로 지속적으로 작업했으며 LinkedIn 외부의 강력한 기여자 및 커미터 커뮤니티를 찾았습니다. Kafka는 현재 Netflix, Uber 및 기타 여러 회사를 포함하여 세계에서 가장 큰 데이터 파이프라인 중 일부에서 사용됩니다.

Kafka의 광범위한 채택은 핵심 프로젝트 주변에 건강한 생태계도 조성했습니다. 전 세계 수십 개국에 활발한 모임 그룹이 있으며 스트림 처리에 대한 현지 토론과 지원을 제공합니다. Apache Kafka와 관련된 수많은 오픈 소스 프로젝트도 있습니다. LinkedIn은 Cruise Control, Kafka Monitor 및 Burrow를 포함하여 몇 가지를 계속 유지하고 있습니다. 상용 제품 외에도 Confluent는 커뮤니티 라이선스(사용 제한이 포함되어 엄격하게 오픈 소스가 아님)에 따라 ksqlDB, 스키마 레지스트리 및 REST 프록시를 포함한 프로젝트를 출시했습니다. 가장 인기 있는 여러 프로젝트가 부록 B에 나열되어 있습니다.

### 상업적 참여
2014년 가을 Jay Kreps, Neha Narkhede 및 Jun Rao는 LinkedIn을 떠나 Apache Kafka에 대한 개발, 엔터프라이즈 지원 및 교육을 제공하는 회사인 Confluent를 설립했습니다. 그들은 또한 Kafka에 클라우드 서비스를 제공하는 다른 회사(예: Heroku)에 합류했습니다. Confluent는 Google과의 파트너십을 통해 Google Cloud Platform의 관리형 Kafka 클러스터와 Amazon Web Services 및 Azure의 유사한 서비스를 제공합니다. Confluent의 다른 주요 이니셔티브 중 하나는 Kafka Summit 회의 시리즈를 조직하는 것입니다. 2016년에 시작하여 매년 미국과 런던에서 회의를 개최하는 Kafka Summit은 커뮤니티가 전 세계적으로 함께 모여 Apache Kafka 및 관련 프로젝트에 대한 지식을 공유할 수 있는 장소를 제공합니다.

### 이름
사람들은 종종 Kafka가 그 이름을 얻은 방법과 응용 프로그램 자체에 대한 구체적인 의미가 있는지 묻습니다. Jay Kreps는 다음과 같은 통찰력을 제공했습니다.

카프카는 쓰기에 최적화된 시스템이라 작가 이름을 쓰는 게 맞다고 생각했다. 나는 대학에서 조명 수업을 많이 들었고 프란츠 카프카를 좋아했습니다. 게다가 이름은 오픈 소스 프로젝트에 대해 멋지게 들렸습니다.

그래서 기본적으로 관계가 많지 않습니다.


## Getting Started with Kafka

이제 Kafka와 그 역사에 대해 모두 알았으므로 이를 설정하고 자체 데이터 파이프라인을 구축할 수 있습니다. 다음 장에서는 Kafka를 설치하고 구성하는 방법을 살펴보겠습니다. 또한 Kafka를 실행할 올바른 하드웨어 선택과 프로덕션 작업으로 이동할 때 염두에 두어야 할 몇 가지 사항에 대해서도 다룰 것입니다.
